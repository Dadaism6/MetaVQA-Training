datasets:
  meta_vqa:
    # data_dir: ${env.data_dir}/datasets
    data_type: images # [images|videos|features]

    build_info:
      # Be careful not to append minus sign (-) before split to avoid itemizing
      annotations:
        train:
          url:
            - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/aokvqa/aokvqa_v1p0_train.json
          storage:
            - /home/chenda/dataset/metavqa/100k_export/merged_train_int.json
        val:
          url:
            - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/aokvqa/aokvqa_v1p0_val.json
          storage:
            - /home/chenda/dataset/metavqa/100k_export/merged_val_int.json
        test:
          url:
            - https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/aokvqa/aokvqa_v1p0_test.json
          storage:
            - /home/chenda/dataset/metavqa/100k_export/merged_test_int.json
      images:
        storage: /home/chenda/dataset/metavqa/